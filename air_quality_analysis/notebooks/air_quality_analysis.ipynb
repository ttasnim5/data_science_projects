{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.chdir('') # set notebook's working directory one up to the project root\n",
    "print(os.getcwd())\n",
    "# necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions from scripts\n",
    "# from scripts.fetch_openAQ_data import fetch_openaq_data\n",
    "# from scripts.process_world_bank_data import process_world_bank_data\n",
    "# from scripts.analyze_data import combine_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch and process data - this was done once already ^ and doesn't need to be done anymore\n",
    "combined_data = pd.read_csv('../data/merged_data.csv')\n",
    "combined_data.columns\n",
    "combined_data[\"Indicator Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize trends\n",
    "sns.barplot(data=combined_data, x='Year', y='PM10')\n",
    "plt.title('Air Quality vs Population Over Time')\n",
    "plt.show()\n",
    "\n",
    "sns.lineplot(data=combined_data, x='Year', y='PM10')\n",
    "plt.title('Air Quality vs Population Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter rows for PM2.5 and PM10 indicators // SPOILER these graphs were useless\n",
    "pm_data = combined_data[combined_data['Indicator Name'].str.contains('PM2.5|PM10', na=False)]\n",
    "\n",
    "# Line plot to compare trends\n",
    "sns.lineplot(data=pm_data, x='Year', y='WB Value', hue='Indicator Name')\n",
    "plt.title('PM2.5 and PM10 Trends Over Time')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate PM2.5/PM10 ratio\n",
    "combined_data['PM2.5_to_PM10'] = combined_data['WB Value'] / combined_data['PM10']\n",
    "\n",
    "# line plot for ratio over time\n",
    "sns.lineplot(data=combined_data, x='Year', y='PM2.5_to_PM10', hue='Country Name')\n",
    "plt.title('PM2.5 to PM10 Ratio Over Time')\n",
    "plt.ylabel('PM2.5/PM10')\n",
    "plt.show()\n",
    "# shows that pm10 generally < pm2.5, explore further later ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# further: explore relationships between air quality indicators like PM10 or pm2.5 and socioeconomic factors (e.g., GDP, population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a dictionary to map indicators to categories\n",
    "indicator_categories = {\n",
    "    'TRADE': ['exports', 'imports', 'trade', 'merchandise'],\n",
    "    'ECONOMIC': ['gdp', 'gni', 'income', 'economic'],\n",
    "    'POPULATION': ['population', 'urban', 'rural'],\n",
    "    'FOOD': ['food', 'agriculture', 'nutrition'],\n",
    "    'HEALTH': ['health', 'mortality', 'life expectancy']\n",
    "}\n",
    "\n",
    "# function to categorize indicators\n",
    "def categorize_indicator(indicator_name):\n",
    "    indicator_lower = indicator_name.lower()\n",
    "    for category, keywords in indicator_categories.items():\n",
    "        if any(keyword in indicator_lower for keyword in keywords):\n",
    "            return category\n",
    "    return 'OTHER'\n",
    "\n",
    "# add category column\n",
    "combined_data['Category'] = combined_data['Indicator Name'].apply(categorize_indicator)\n",
    "\n",
    "# count indicators per category\n",
    "category_counts = combined_data['Category'].value_counts()\n",
    "print(\"Indicators per category:\")\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pivot the data to create a matrix with countries as rows and indicators as columns\n",
    "pivot_df = combined_data.pivot_table(\n",
    "    index=['Country Name', 'Year', 'PM10'],\n",
    "    columns='Indicator Name',\n",
    "    values='WB Value'\n",
    ").reset_index()\n",
    "\n",
    "# select columns with at least 50% non-null values\n",
    "threshold = len(pivot_df) * 0.5\n",
    "pivot_df = pivot_df.loc[:, pivot_df.notna().sum() > threshold]\n",
    "\n",
    "# standardize the data (excluding PM10)\n",
    "columns_to_standardize = [col for col in pivot_df.columns if col not in ['Country Name', 'Year', 'PM10']]\n",
    "scaler = StandardScaler()\n",
    "pivot_df[columns_to_standardize] = scaler.fit_transform(pivot_df[columns_to_standardize].fillna(0))\n",
    "\n",
    "# calculate correlation with PM10\n",
    "correlations = pivot_df[columns_to_standardize].corrwith(pivot_df['PM10']).sort_values(ascending=False)\n",
    "\n",
    "# plot top correlations\n",
    "plt.figure(figsize=(12, 6))\n",
    "correlations.head(10).plot(kind='bar')\n",
    "plt.title('Top 10 Indicators Correlated with PM10')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 positively correlated indicators with PM10:\")\n",
    "print(correlations.head().to_frame('correlation'))\n",
    "\n",
    "print(\"\\nTop 5 negatively correlated indicators with PM10:\")\n",
    "print(correlations.tail().to_frame('correlation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# select numeric columns\n",
    "numeric_columns = pivot_df.select_dtypes(include=[np.number]).columns\n",
    "# create mean imputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "# impute missing values\n",
    "imputed_data = imputer.fit_transform(pivot_df[numeric_columns])\n",
    "imputed_df = pd.DataFrame(imputed_data, columns=numeric_columns)\n",
    "\n",
    "# standardize the imputed numeric data\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(imputed_df)\n",
    "standardized_df = pd.DataFrame(standardized_data, columns=numeric_columns)\n",
    "\n",
    "# add back non-numeric columns\n",
    "final_df = pd.concat([pivot_df[['Country Name', 'Year']], standardized_df], axis=1)\n",
    "\n",
    "print(\"Data shape after cleaning:\", final_df.shape)\n",
    "print(\"\\nFirst few rows of cleaned and standardized data:\")\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# select trade-related indicators\n",
    "trade_indicators = [col for col in numeric_columns if 'export' in col.lower()]\n",
    "\n",
    "# perform PCA\n",
    "pca = PCA()\n",
    "trade_data = standardized_df[trade_indicators]\n",
    "trade_pca = pca.fit_transform(trade_data)\n",
    "\n",
    "# explained variance\n",
    "print(\"Explained variance ratio:\")\n",
    "print(pca.explained_variance_ratio_)\n",
    "# this is a scree plot but what IS a scree plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), \n",
    "         np.cumsum(pca.explained_variance_ratio_), 'bo-')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA Scree Plot')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# economic indicators\n",
    "economic_indicators = [col for col in standardized_df.columns \n",
    "                      if any(term in col.lower() \n",
    "                            for term in ['gdp', 'trade', 'export', 'import'])]\n",
    "\n",
    "# prepare data for clustering\n",
    "X = standardized_df[economic_indicators]\n",
    "\n",
    "# perform K-means clustering\n",
    "n_clusters = 3  # Example number of clusters\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "# calculate silhouette score\n",
    "silhouette_avg = silhouette_score(X, clusters)\n",
    "# cluster labels\n",
    "final_df['Cluster'] = clusters\n",
    "\n",
    "# correlation matrix for economic indicators\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "# correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix of Economic Indicators')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSilhouette Score:\", silhouette_avg)\n",
    "print(\"\\nCluster Sizes:\")\n",
    "print(pd.Series(clusters).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cluster characteristics\n",
    "cluster_means = final_df.groupby('Cluster')[economic_indicators].mean()\n",
    "# standardize the values for visualization\n",
    "cluster_means_std = (cluster_means - cluster_means.mean()) / cluster_means.std()\n",
    "\n",
    "# heatmap of cluster characteristics\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.heatmap(cluster_means_std, cmap='RdYlBu', center=0, annot=True, fmt='.2f')\n",
    "plt.title('Standardized Characteristics of Each Cluster')\n",
    "plt.ylabel('Cluster')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# print cluster membership\n",
    "print(\"\\nCluster Memberships:\")\n",
    "print(final_df[['Country Name', 'Year', 'Cluster']].sort_values('Cluster'))\n",
    "\n",
    "# calculate top distinguishing features for each cluster\n",
    "print(\"\\nTop Distinguishing Features per Cluster:\")\n",
    "for cluster in range(3):\n",
    "    cluster_data = cluster_means.loc[cluster]\n",
    "    top_features = cluster_data.sort_values(ascending=False).head(3)\n",
    "    print(f\"\\nCluster {cluster} top features:\")\n",
    "    print(top_features)\n",
    "    # this is not showing the top associated indicators for cluster 2 ? why"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
